{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the seed value for the notebook so the results are reproducible\n",
    "from numpy.random import seed\n",
    "seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Smartphone Activity Detector\n",
    "\n",
    "http://archive.ics.uci.edu/ml/datasets/Smartphone-Based+Recognition+of+Human+Activities+and+Postural+Transitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective\n",
    "\n",
    "Predict human activity using smartphone sensor data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre-Processing\n",
    "Note: This dataset has already been scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Data Paths\n",
    "X_training_data = os.path.join(\"..\", \"Resources\", \"Train\", \"X_train.txt\")\n",
    "y_training_data = os.path.join(\"..\", \"Resources\", \"Train\", \"y_train.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing Data Paths\n",
    "X_testing_data = os.path.join(\"..\", \"Resources\", \"Test\", \"X_test.txt\")\n",
    "y_testing_data = os.path.join(\"..\", \"Resources\", \"Test\", \"y_test.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>551</th>\n",
       "      <th>552</th>\n",
       "      <th>553</th>\n",
       "      <th>554</th>\n",
       "      <th>555</th>\n",
       "      <th>556</th>\n",
       "      <th>557</th>\n",
       "      <th>558</th>\n",
       "      <th>559</th>\n",
       "      <th>560</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.039480</td>\n",
       "      <td>-0.002131</td>\n",
       "      <td>-0.029067</td>\n",
       "      <td>-0.998348</td>\n",
       "      <td>-0.982945</td>\n",
       "      <td>-0.971273</td>\n",
       "      <td>-0.998702</td>\n",
       "      <td>-0.983315</td>\n",
       "      <td>-0.974000</td>\n",
       "      <td>-0.802537</td>\n",
       "      <td>...</td>\n",
       "      <td>0.202804</td>\n",
       "      <td>-0.603199</td>\n",
       "      <td>-0.860677</td>\n",
       "      <td>0.053477</td>\n",
       "      <td>-0.007435</td>\n",
       "      <td>-0.732626</td>\n",
       "      <td>0.703511</td>\n",
       "      <td>-0.845092</td>\n",
       "      <td>0.180261</td>\n",
       "      <td>-0.047436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.039978</td>\n",
       "      <td>-0.005153</td>\n",
       "      <td>-0.022651</td>\n",
       "      <td>-0.995482</td>\n",
       "      <td>-0.977314</td>\n",
       "      <td>-0.984760</td>\n",
       "      <td>-0.996415</td>\n",
       "      <td>-0.975835</td>\n",
       "      <td>-0.985973</td>\n",
       "      <td>-0.798477</td>\n",
       "      <td>...</td>\n",
       "      <td>0.440079</td>\n",
       "      <td>-0.404427</td>\n",
       "      <td>-0.761847</td>\n",
       "      <td>-0.118559</td>\n",
       "      <td>0.177899</td>\n",
       "      <td>0.100699</td>\n",
       "      <td>0.808529</td>\n",
       "      <td>-0.849230</td>\n",
       "      <td>0.180610</td>\n",
       "      <td>-0.042271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.039785</td>\n",
       "      <td>-0.011809</td>\n",
       "      <td>-0.028916</td>\n",
       "      <td>-0.996194</td>\n",
       "      <td>-0.988569</td>\n",
       "      <td>-0.993256</td>\n",
       "      <td>-0.996994</td>\n",
       "      <td>-0.988526</td>\n",
       "      <td>-0.993135</td>\n",
       "      <td>-0.798477</td>\n",
       "      <td>...</td>\n",
       "      <td>0.430891</td>\n",
       "      <td>-0.138373</td>\n",
       "      <td>-0.491604</td>\n",
       "      <td>-0.036788</td>\n",
       "      <td>-0.012892</td>\n",
       "      <td>0.640011</td>\n",
       "      <td>-0.485366</td>\n",
       "      <td>-0.848947</td>\n",
       "      <td>0.181907</td>\n",
       "      <td>-0.040826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.038758</td>\n",
       "      <td>-0.002289</td>\n",
       "      <td>-0.023863</td>\n",
       "      <td>-0.998241</td>\n",
       "      <td>-0.986774</td>\n",
       "      <td>-0.993115</td>\n",
       "      <td>-0.998216</td>\n",
       "      <td>-0.986479</td>\n",
       "      <td>-0.993825</td>\n",
       "      <td>-0.801982</td>\n",
       "      <td>...</td>\n",
       "      <td>0.137735</td>\n",
       "      <td>-0.366214</td>\n",
       "      <td>-0.702490</td>\n",
       "      <td>0.123320</td>\n",
       "      <td>0.122542</td>\n",
       "      <td>0.693578</td>\n",
       "      <td>-0.615971</td>\n",
       "      <td>-0.848164</td>\n",
       "      <td>0.185124</td>\n",
       "      <td>-0.037080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.038988</td>\n",
       "      <td>0.004109</td>\n",
       "      <td>-0.017340</td>\n",
       "      <td>-0.997438</td>\n",
       "      <td>-0.993485</td>\n",
       "      <td>-0.996692</td>\n",
       "      <td>-0.997522</td>\n",
       "      <td>-0.993494</td>\n",
       "      <td>-0.996916</td>\n",
       "      <td>-0.801982</td>\n",
       "      <td>...</td>\n",
       "      <td>0.074999</td>\n",
       "      <td>-0.554902</td>\n",
       "      <td>-0.844224</td>\n",
       "      <td>0.082632</td>\n",
       "      <td>-0.143439</td>\n",
       "      <td>0.275041</td>\n",
       "      <td>-0.368224</td>\n",
       "      <td>-0.849927</td>\n",
       "      <td>0.184795</td>\n",
       "      <td>-0.035326</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 561 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0  0.039480 -0.002131 -0.029067 -0.998348 -0.982945 -0.971273 -0.998702   \n",
       "1  0.039978 -0.005153 -0.022651 -0.995482 -0.977314 -0.984760 -0.996415   \n",
       "2  0.039785 -0.011809 -0.028916 -0.996194 -0.988569 -0.993256 -0.996994   \n",
       "3  0.038758 -0.002289 -0.023863 -0.998241 -0.986774 -0.993115 -0.998216   \n",
       "4  0.038988  0.004109 -0.017340 -0.997438 -0.993485 -0.996692 -0.997522   \n",
       "\n",
       "        7         8         9    ...       551       552       553       554  \\\n",
       "0 -0.983315 -0.974000 -0.802537  ...  0.202804 -0.603199 -0.860677  0.053477   \n",
       "1 -0.975835 -0.985973 -0.798477  ...  0.440079 -0.404427 -0.761847 -0.118559   \n",
       "2 -0.988526 -0.993135 -0.798477  ...  0.430891 -0.138373 -0.491604 -0.036788   \n",
       "3 -0.986479 -0.993825 -0.801982  ...  0.137735 -0.366214 -0.702490  0.123320   \n",
       "4 -0.993494 -0.996916 -0.801982  ...  0.074999 -0.554902 -0.844224  0.082632   \n",
       "\n",
       "        555       556       557       558       559       560  \n",
       "0 -0.007435 -0.732626  0.703511 -0.845092  0.180261 -0.047436  \n",
       "1  0.177899  0.100699  0.808529 -0.849230  0.180610 -0.042271  \n",
       "2 -0.012892  0.640011 -0.485366 -0.848947  0.181907 -0.040826  \n",
       "3  0.122542  0.693578 -0.615971 -0.848164  0.185124 -0.037080  \n",
       "4 -0.143439  0.275041 -0.368224 -0.849927  0.184795 -0.035326  \n",
       "\n",
       "[5 rows x 561 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the training data into a dataframe\n",
    "X_train_df = pd.read_csv(\n",
    "    X_training_data, delimiter=\" \", skiprows=1, header=None)\n",
    "X_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the dataframe to a numpy array for Keras\n",
    "X_train = X_train_df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the training labels as a dataframe\n",
    "y_train_df = pd.read_csv(y_training_data)\n",
    "\n",
    "# One-hot encode the integer labels\n",
    "# 1 WALKING\n",
    "# 2 WALKING_UPSTAIRS\n",
    "# 3 WALKING_DOWNSTAIRS\n",
    "# 4 SITTING\n",
    "# 5 STANDING\n",
    "# 6 LAYING\n",
    "# 7 STAND_TO_SIT\n",
    "# 8 SIT_TO_STAND\n",
    "# 9 SIT_TO_LIE\n",
    "# 10 LIE_TO_SIT\n",
    "# 11 STAND_TO_LIE\n",
    "# 12 LIE_TO_STAND\n",
    "\n",
    "y_train = to_categorical(y_train_df)\n",
    "y_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3161, 561)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the testing data\n",
    "X_test_df = pd.read_csv(X_testing_data, delimiter=\" \", skiprows=1, header=None)\n",
    "X_test = X_test_df.values\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3161, 13)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the testing labels\n",
    "y_test_df = pd.read_csv(y_testing_data)\n",
    "# One-hot encode the integer labels\n",
    "y_test = to_categorical(y_test_df)\n",
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a Deep Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty sequential model\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the first layer where the input dimensions are the 561 columns of the training data\n",
    "model.add(Dense(100, activation='relu', input_dim=X_train.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a second hidden layer\n",
    "model.add(Dense(100, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7766, 13)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The output layer has 13 columns that are one-hot encoded\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add output layer\n",
    "model.add(Dense(y_train.shape[1], activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model using categorical_crossentropy for the loss function, the adam optimizer,\n",
    "# and add accuracy to the training metrics\n",
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=\"adam\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7766 samples\n",
      "Epoch 1/100\n",
      "7766/7766 - 1s - loss: 0.5890 - accuracy: 0.8043\n",
      "Epoch 2/100\n",
      "7766/7766 - 0s - loss: 0.2218 - accuracy: 0.9104\n",
      "Epoch 3/100\n",
      "7766/7766 - 0s - loss: 0.1652 - accuracy: 0.9351\n",
      "Epoch 4/100\n",
      "7766/7766 - 0s - loss: 0.1190 - accuracy: 0.9545\n",
      "Epoch 5/100\n",
      "7766/7766 - 0s - loss: 0.1106 - accuracy: 0.9598\n",
      "Epoch 6/100\n",
      "7766/7766 - 0s - loss: 0.0990 - accuracy: 0.9620\n",
      "Epoch 7/100\n",
      "7766/7766 - 0s - loss: 0.1043 - accuracy: 0.9600\n",
      "Epoch 8/100\n",
      "7766/7766 - 0s - loss: 0.0870 - accuracy: 0.9652\n",
      "Epoch 9/100\n",
      "7766/7766 - 0s - loss: 0.0881 - accuracy: 0.9660\n",
      "Epoch 10/100\n",
      "7766/7766 - 0s - loss: 0.0733 - accuracy: 0.9717\n",
      "Epoch 11/100\n",
      "7766/7766 - 0s - loss: 0.0891 - accuracy: 0.9669\n",
      "Epoch 12/100\n",
      "7766/7766 - 0s - loss: 0.0728 - accuracy: 0.9717\n",
      "Epoch 13/100\n",
      "7766/7766 - 0s - loss: 0.0633 - accuracy: 0.9757\n",
      "Epoch 14/100\n",
      "7766/7766 - 0s - loss: 0.0728 - accuracy: 0.9708\n",
      "Epoch 15/100\n",
      "7766/7766 - 0s - loss: 0.0564 - accuracy: 0.9788\n",
      "Epoch 16/100\n",
      "7766/7766 - 0s - loss: 0.0619 - accuracy: 0.9762\n",
      "Epoch 17/100\n",
      "7766/7766 - 0s - loss: 0.0531 - accuracy: 0.9808\n",
      "Epoch 18/100\n",
      "7766/7766 - 0s - loss: 0.0599 - accuracy: 0.9770\n",
      "Epoch 19/100\n",
      "7766/7766 - 0s - loss: 0.0487 - accuracy: 0.9811\n",
      "Epoch 20/100\n",
      "7766/7766 - 0s - loss: 0.0554 - accuracy: 0.9786\n",
      "Epoch 21/100\n",
      "7766/7766 - 0s - loss: 0.0546 - accuracy: 0.9775\n",
      "Epoch 22/100\n",
      "7766/7766 - 0s - loss: 0.0498 - accuracy: 0.9815\n",
      "Epoch 23/100\n",
      "7766/7766 - 0s - loss: 0.0561 - accuracy: 0.9764\n",
      "Epoch 24/100\n",
      "7766/7766 - 0s - loss: 0.0465 - accuracy: 0.9809\n",
      "Epoch 25/100\n",
      "7766/7766 - 0s - loss: 0.0494 - accuracy: 0.9818\n",
      "Epoch 26/100\n",
      "7766/7766 - 0s - loss: 0.0546 - accuracy: 0.9793\n",
      "Epoch 27/100\n",
      "7766/7766 - 0s - loss: 0.0430 - accuracy: 0.9842\n",
      "Epoch 28/100\n",
      "7766/7766 - 0s - loss: 0.0519 - accuracy: 0.9793\n",
      "Epoch 29/100\n",
      "7766/7766 - 0s - loss: 0.0358 - accuracy: 0.9875\n",
      "Epoch 30/100\n",
      "7766/7766 - 0s - loss: 0.0458 - accuracy: 0.9827\n",
      "Epoch 31/100\n",
      "7766/7766 - 0s - loss: 0.0308 - accuracy: 0.9885\n",
      "Epoch 32/100\n",
      "7766/7766 - 0s - loss: 0.0333 - accuracy: 0.9864\n",
      "Epoch 33/100\n",
      "7766/7766 - 0s - loss: 0.0554 - accuracy: 0.9788\n",
      "Epoch 34/100\n",
      "7766/7766 - 0s - loss: 0.0387 - accuracy: 0.9849\n",
      "Epoch 35/100\n",
      "7766/7766 - 0s - loss: 0.0323 - accuracy: 0.9889\n",
      "Epoch 36/100\n",
      "7766/7766 - 0s - loss: 0.0344 - accuracy: 0.9873\n",
      "Epoch 37/100\n",
      "7766/7766 - 0s - loss: 0.0297 - accuracy: 0.9888\n",
      "Epoch 38/100\n",
      "7766/7766 - 0s - loss: 0.0306 - accuracy: 0.9884\n",
      "Epoch 39/100\n",
      "7766/7766 - 0s - loss: 0.0318 - accuracy: 0.9880\n",
      "Epoch 40/100\n",
      "7766/7766 - 0s - loss: 0.0438 - accuracy: 0.9845\n",
      "Epoch 41/100\n",
      "7766/7766 - 0s - loss: 0.0459 - accuracy: 0.9842\n",
      "Epoch 42/100\n",
      "7766/7766 - 0s - loss: 0.0273 - accuracy: 0.9898\n",
      "Epoch 43/100\n",
      "7766/7766 - 0s - loss: 0.0197 - accuracy: 0.9923\n",
      "Epoch 44/100\n",
      "7766/7766 - 0s - loss: 0.0315 - accuracy: 0.9883\n",
      "Epoch 45/100\n",
      "7766/7766 - 0s - loss: 0.0544 - accuracy: 0.9825\n",
      "Epoch 46/100\n",
      "7766/7766 - 0s - loss: 0.0244 - accuracy: 0.9902\n",
      "Epoch 47/100\n",
      "7766/7766 - 0s - loss: 0.0271 - accuracy: 0.9900\n",
      "Epoch 48/100\n",
      "7766/7766 - 0s - loss: 0.0199 - accuracy: 0.9916\n",
      "Epoch 49/100\n",
      "7766/7766 - 0s - loss: 0.0248 - accuracy: 0.9920\n",
      "Epoch 50/100\n",
      "7766/7766 - 0s - loss: 0.0328 - accuracy: 0.9874\n",
      "Epoch 51/100\n",
      "7766/7766 - 0s - loss: 0.0219 - accuracy: 0.9919\n",
      "Epoch 52/100\n",
      "7766/7766 - 0s - loss: 0.0261 - accuracy: 0.9898\n",
      "Epoch 53/100\n",
      "7766/7766 - 0s - loss: 0.0325 - accuracy: 0.9875\n",
      "Epoch 54/100\n",
      "7766/7766 - 0s - loss: 0.0237 - accuracy: 0.9901\n",
      "Epoch 55/100\n",
      "7766/7766 - 0s - loss: 0.0190 - accuracy: 0.9934\n",
      "Epoch 56/100\n",
      "7766/7766 - 0s - loss: 0.0272 - accuracy: 0.9894\n",
      "Epoch 57/100\n",
      "7766/7766 - 0s - loss: 0.0259 - accuracy: 0.9905\n",
      "Epoch 58/100\n",
      "7766/7766 - 0s - loss: 0.0240 - accuracy: 0.9911\n",
      "Epoch 59/100\n",
      "7766/7766 - 0s - loss: 0.0199 - accuracy: 0.9921\n",
      "Epoch 60/100\n",
      "7766/7766 - 0s - loss: 0.0168 - accuracy: 0.9941\n",
      "Epoch 61/100\n",
      "7766/7766 - 0s - loss: 0.0219 - accuracy: 0.9928\n",
      "Epoch 62/100\n",
      "7766/7766 - 0s - loss: 0.0164 - accuracy: 0.9938\n",
      "Epoch 63/100\n",
      "7766/7766 - 0s - loss: 0.0073 - accuracy: 0.9974\n",
      "Epoch 64/100\n",
      "7766/7766 - 0s - loss: 0.0152 - accuracy: 0.9938\n",
      "Epoch 65/100\n",
      "7766/7766 - 0s - loss: 0.0353 - accuracy: 0.9876\n",
      "Epoch 66/100\n",
      "7766/7766 - 0s - loss: 0.0159 - accuracy: 0.9946\n",
      "Epoch 67/100\n",
      "7766/7766 - 0s - loss: 0.0191 - accuracy: 0.9919\n",
      "Epoch 68/100\n",
      "7766/7766 - 0s - loss: 0.0170 - accuracy: 0.9921\n",
      "Epoch 69/100\n",
      "7766/7766 - 0s - loss: 0.0087 - accuracy: 0.9965\n",
      "Epoch 70/100\n",
      "7766/7766 - 0s - loss: 0.0086 - accuracy: 0.9963\n",
      "Epoch 71/100\n",
      "7766/7766 - 0s - loss: 0.0188 - accuracy: 0.9927\n",
      "Epoch 72/100\n",
      "7766/7766 - 0s - loss: 0.0219 - accuracy: 0.9925\n",
      "Epoch 73/100\n",
      "7766/7766 - 0s - loss: 0.0213 - accuracy: 0.9927\n",
      "Epoch 74/100\n",
      "7766/7766 - 0s - loss: 0.0200 - accuracy: 0.9921\n",
      "Epoch 75/100\n",
      "7766/7766 - 0s - loss: 0.0154 - accuracy: 0.9939\n",
      "Epoch 76/100\n",
      "7766/7766 - 0s - loss: 0.0204 - accuracy: 0.9929\n",
      "Epoch 77/100\n",
      "7766/7766 - 0s - loss: 0.0073 - accuracy: 0.9972\n",
      "Epoch 78/100\n",
      "7766/7766 - 0s - loss: 0.0127 - accuracy: 0.9951\n",
      "Epoch 79/100\n",
      "7766/7766 - 0s - loss: 0.0084 - accuracy: 0.9973\n",
      "Epoch 80/100\n",
      "7766/7766 - 0s - loss: 0.0113 - accuracy: 0.9955\n",
      "Epoch 81/100\n",
      "7766/7766 - 0s - loss: 0.0151 - accuracy: 0.9941\n",
      "Epoch 82/100\n",
      "7766/7766 - 0s - loss: 0.0204 - accuracy: 0.9923\n",
      "Epoch 83/100\n",
      "7766/7766 - 0s - loss: 0.0148 - accuracy: 0.9943\n",
      "Epoch 84/100\n",
      "7766/7766 - 0s - loss: 0.0148 - accuracy: 0.9941\n",
      "Epoch 85/100\n",
      "7766/7766 - 0s - loss: 0.0153 - accuracy: 0.9958\n",
      "Epoch 86/100\n",
      "7766/7766 - 0s - loss: 0.0236 - accuracy: 0.9916\n",
      "Epoch 87/100\n",
      "7766/7766 - 0s - loss: 0.0197 - accuracy: 0.9928\n",
      "Epoch 88/100\n",
      "7766/7766 - 0s - loss: 0.0050 - accuracy: 0.9986\n",
      "Epoch 89/100\n",
      "7766/7766 - 0s - loss: 0.0040 - accuracy: 0.9986\n",
      "Epoch 90/100\n",
      "7766/7766 - 0s - loss: 0.0273 - accuracy: 0.9891\n",
      "Epoch 91/100\n",
      "7766/7766 - 0s - loss: 0.0227 - accuracy: 0.9936\n",
      "Epoch 92/100\n",
      "7766/7766 - 0s - loss: 0.0141 - accuracy: 0.9946\n",
      "Epoch 93/100\n",
      "7766/7766 - 0s - loss: 0.0088 - accuracy: 0.9961\n",
      "Epoch 94/100\n",
      "7766/7766 - 0s - loss: 0.0110 - accuracy: 0.9964\n",
      "Epoch 95/100\n",
      "7766/7766 - 0s - loss: 0.0041 - accuracy: 0.9986\n",
      "Epoch 96/100\n",
      "7766/7766 - 0s - loss: 0.0066 - accuracy: 0.9976\n",
      "Epoch 97/100\n",
      "7766/7766 - 0s - loss: 0.0231 - accuracy: 0.9912\n",
      "Epoch 98/100\n",
      "7766/7766 - 0s - loss: 0.0094 - accuracy: 0.9967\n",
      "Epoch 99/100\n",
      "7766/7766 - 0s - loss: 0.0065 - accuracy: 0.9978\n",
      "Epoch 100/100\n",
      "7766/7766 - 0s - loss: 0.0125 - accuracy: 0.9950\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x13f31908908>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the training data to fit (train) the model\n",
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=100,\n",
    "    shuffle=True,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save(\"smartphone_trained.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "from tensorflow.keras.models import load_model\n",
    "model = load_model(\"smartphone_trained.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3161/1 - 0s - loss: 0.2024 - accuracy: 0.9399\n",
      "Loss: 0.40362871286663116, Accuracy: 0.9398924112319946\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the training data\n",
    "model_loss, model_accuracy = model.evaluate(X_test, y_test, verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 561)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grab just one data point to test with\n",
    "test = np.expand_dims(X_test[0], axis=0)\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: [5]\n"
     ]
    }
   ],
   "source": [
    "# Make a prediction. The result should be 5 - STANDING\n",
    "print(f\"Predicted class: {model.predict_classes(test)}\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
